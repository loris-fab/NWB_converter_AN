{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ac0b88",
   "metadata": {},
   "source": [
    "# Preprocessing .mat for NWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee9f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import LO_NWB_conv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b848cdc",
   "metadata": {},
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0785ecbc",
   "metadata": {},
   "source": [
    "## mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5df6c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import h5py\n",
    "\n",
    "WRAO039 = \"data/mouse_anastasia/WR/AO039_20190626.mat\"  \n",
    "WRAO027 = \"data/mouse_anastasia/WR/AO027_20181101.mat\"\n",
    "WnonRAO084 = \"data/mouse_anastasia/WnonR/AO084_20210507.mat\"\n",
    "WnonRAO086 = \"data/mouse_anastasia/WnonR/AO086_20210617.mat\"\n",
    "\n",
    "with h5py.File(WRAO039, 'r') as f:\n",
    "    data_group = f['Data']\n",
    "    data_ref = f[\"#refs#\"]\n",
    "    #print(\"R√©f√©rences trouv√©es :\")\n",
    "    #for key in data_ref.keys():\n",
    "    #    print(f\" - {key} ‚Üí shape: {data_ref[key].shape}, dtype: {data_ref[key].dtype}\")\n",
    "    print(\"Contenu de 'Data' :\")\n",
    "    for key in data_group.keys():\n",
    "        print(f\" - {key} ‚Üí shape: {data_group[key].shape}, dtype: {data_group[key].dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c1b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(WRAO039, 'r') as f:\n",
    "\tdata_group = f['Data'] if 'Data' in f else f\n",
    "\tWRAO039 = {key: data_group[key][()] for key in data_group.keys()}\n",
    "\n",
    "with h5py.File(WRAO027, 'r') as f:\n",
    "\tdata_group = f['Data'] if 'Data' in f else f\n",
    "\tWRAO027 = {key: data_group[key][()] for key in data_group.keys()}\n",
    "\n",
    "with h5py.File(WnonRAO084, 'r') as f:\n",
    "\tdata_group = f['Data'] if 'Data' in f else f\n",
    "\tWnonRAO084 = {key: data_group[key][()] for key in data_group.keys()}\n",
    "\n",
    "with h5py.File(WnonRAO086, 'r') as f:\n",
    "\tdata_group = f['Data'] if 'Data' in f else f\n",
    "\tWnonRAO086 = {key: data_group[key][()] for key in data_group.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfff0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison WRAO039 et WRAO027\n",
    "keys_WRAO039 = set(WRAO039.keys())\n",
    "keys_WRAO027 = set(WRAO027.keys())\n",
    "\n",
    "same_keys = keys_WRAO039 == keys_WRAO027\n",
    "print(\"Les deux dictionnaires ont les m√™mes cl√©s :\", same_keys)\n",
    "\n",
    "if not same_keys:\n",
    "    print(\"Cl√©s uniquement dans WRAO039 :\", keys_WRAO039 - keys_WRAO027)\n",
    "    print(\"Cl√©s uniquement dans WRAO027 :\", keys_WRAO027 - keys_WRAO039)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae62231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison WnonRAO084 et WnonRAO086\n",
    "keys_WnonRAO084 = set(WnonRAO084.keys())\n",
    "keys_WnonRAO086 = set(WnonRAO086.keys())\n",
    "\n",
    "same_keys = keys_WnonRAO084 == keys_WnonRAO086\n",
    "print(\"Les deux dictionnaires ont les m√™mes cl√©s :\", same_keys)\n",
    "\n",
    "if not same_keys:\n",
    "    print(\"Cl√©s uniquement dans WnonRAO084 :\", keys_WnonRAO084 - keys_WnonRAO086)\n",
    "    print(\"Cl√©s uniquement dans WnonRAO086 :\", keys_WnonRAO086 - keys_WnonRAO084)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee44381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comaraison WR et WnonR\n",
    "keys_WR = set(WRAO039.keys())\n",
    "keys_WnonR = set(WnonRAO084.keys())\n",
    "same_keys = keys_WR == keys_WnonR\n",
    "print(\"Les deux dictionnaires ont les m√™mes cl√©s :\", same_keys)\n",
    "\n",
    "if not same_keys:\n",
    "    print(\"Cl√©s uniquement dans WR :\", keys_WR - keys_WnonR)\n",
    "    print(\"Cl√©s uniquement dans WnonR :\", keys_WnonR - keys_WR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Non\" in subject_info.get(\"Session Type\", \"Unknown\").strip():\n",
    "    Rewarded = False\n",
    "else:\n",
    "    Rewarded = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fb2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(WRAO039, 'r') as f:\n",
    "\tdata_group = f['Data'] if 'Data' in f else f\n",
    "\tdata = {key: data_group[key][()] for key in data_group.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db2f5a",
   "metadata": {},
   "source": [
    "## CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702fda3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_data = pd.read_csv(\"data/Subject_Session_Selection.csv\", sep=\";\")\n",
    "csv_data.columns = csv_data.columns.str.strip() \n",
    "csv_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1cf60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mouse = ''.join(chr(c) for c in WnonRAO084['mouse'].flatten())\n",
    "date = ''.join(chr(c) for c in WnonRAO084['date'].flatten())\n",
    "session_name = f\"{mouse}_{date}\"  \n",
    "\n",
    "try:\n",
    "    subject_info = csv_data[csv_data['Session'].astype(str).str.strip() == session_name].iloc[0]\n",
    "except IndexError:\n",
    "    raise ValueError(f\"Session {session_name} not found in the CSV file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e142f12d",
   "metadata": {},
   "source": [
    " # TOTAL _-_-_-_-_-_-_-_\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "851bb2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tous les fichiers ont √©t√© supprim√©s du dossier data/nwb_output.\n",
      "**************************************************************************\n",
      "-_-_-_-_-_-_-_-_-_-_-_-_-_-_- NWB conversion _-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
      " \n",
      "üìÉ Creating config file for NWB conversion :\n",
      "   - data/AO027_20181101_config.yaml\n",
      " \n",
      "üìë Created NWB file\n",
      "     o üìå Add general metadata\n",
      "         - Subject metadata\n",
      "         - Session metadata\n",
      "         - Device metadata\n",
      "         - Extracellular electrophysiology metadata\n",
      "     o üì∂ Add acquisition container\n",
      "     o üß† Add units container\n",
      "     o ‚öôÔ∏è Add processing container\n",
      "         - Behavior data\n",
      "         - No ephys data for AN sessions\n",
      " \n",
      "üîé Validating NWB file before saving...\n",
      "     o ‚úÖ File is valid, no errors detected.\n",
      " \n",
      "üíæ Saving NWB file\n",
      "     o üìÇ NWB file saved at:\n",
      "         - data/nwb_output/AO027_20181101_134512_2025_07_15.11-48-20.nwb\n",
      "**************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Supprimer tous les fichiers dans le dossier NWB output\n",
    "for file in os.listdir(\"data/nwb_output\"):\n",
    "    file_path = os.path.join(\"data/nwb_output\", file)\n",
    "    if os.path.isfile(file_path):\n",
    "        os.remove(file_path)\n",
    "print(\"Tous les fichiers ont √©t√© supprim√©s du dossier data/nwb_output.\")\n",
    "\n",
    "filename = \"data/mouse_anastasia/WR/AO027_20181101.mat\" # Chemin vers le fichier .mat\n",
    "importlib.reload(LO_NWB_conv)\n",
    "nwb_path = LO_NWB_conv.convert_data_to_nwb_an(mat_file=filename, output_folder=\"data/nwb_output\", output_folder_config=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b897cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0bc660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nwb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
