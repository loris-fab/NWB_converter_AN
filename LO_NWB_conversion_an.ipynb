{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ac0b88",
   "metadata": {},
   "source": [
    "# Preprocessing .mat for NWB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c5b16",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee9f332",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_subject_data_folder' from 'utils.server_paths' (/Users/lorisfabbro/Desktop/Divers/LSENS/NWB_converter_AN/utils/server_paths.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mNWB_conversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (convert_data_to_nwb_an)\n",
      "File \u001b[0;32m~/Desktop/Divers/LSENS/NWB_converter_AN/NWB_conversion.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconverters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfacemap_to_nwb\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_facemap_data\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbehavior_converter_misc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find_training_days\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver_paths\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (get_nwb_folder, get_subject_analysis_folder, get_experimenter_analysis_folder,\n\u001b[1;32m     24\u001b[0m                                 get_subject_data_folder, get_dlc_file_path, get_facemap_file_path)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconvert_data_to_nwb_an\u001b[39m(config_file, output_folder, with_time_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    :param config_file: Path to the yaml config file containing mouse ID and metadata for the session to convert\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    :param output_folder: Path to the folder to save NWB files\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    Converts data from a config file to an NWB file.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_subject_data_folder' from 'utils.server_paths' (/Users/lorisfabbro/Desktop/Divers/LSENS/NWB_converter_AN/utils/server_paths.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from NWB_conversion import (convert_data_to_nwb_an)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1694bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def search_and_open_mat(mouse_id: str, last_done_day: str):\n",
    "    \"\"\"\n",
    "    Search and open a .mat file from a mounted network drive (/Volumes/WR on macOS).\n",
    "\n",
    "    :param mouse_id: Mouse ID to search  e.g., \"AO039\"\n",
    "    :param last_done_day: Last done day as a string e.g., \"20190626\"\n",
    "    :return: Path to the found .mat file\n",
    "    \"\"\"\n",
    "\n",
    "    # Build the full path to the .mat file\n",
    "    filename = f\"{mouse_id}_{last_done_day}.mat\"\n",
    "    file_path = os.path.join(\"/Volumes/WR\", filename)\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "    # Try opening the file using h5py (for .mat v7.3 HDF5 format)\n",
    "    try:\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            print(f\"‚úÖ File '{filename}' opened successfully.\")\n",
    "\n",
    "    except PermissionError as e:\n",
    "        print(\"‚ùå Permission denied: Python can't access this file.\")\n",
    "        print(\"üí° Check macOS privacy settings (System Preferences > Privacy > Full Disk Access).\")\n",
    "        raise e\n",
    "\n",
    "    except OSError as e:\n",
    "        print(\"‚ùå Error opening file. Is it an HDF5 (MATLAB v7.3) .mat file?\")\n",
    "        raise e\n",
    "    \n",
    "    return file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6bef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def files_to_config(mat_file, csv_file, output_path=\"data/config.yaml\"):\n",
    "    \"\"\"\n",
    "    Converts a .mat file and csv_file into a .yaml configuration file for the NWB pipeline.\n",
    "\n",
    "    :param mat_file: Path to the .mat file\n",
    "    :return: Configuration dictionary + path to the yaml file\n",
    "    \"\"\"\n",
    "    # PART 1: Load the .mat file and extract metadata\n",
    "    # Load the .mat file\n",
    "    with h5py.File(mat_file, 'r') as f:\n",
    "        data_group = f['Data'] if 'Data' in f else f\n",
    "        data = {key: data_group[key][()] for key in data_group.keys()}\n",
    "\n",
    "    # Extract relevant information\n",
    "    mouse = ''.join(chr(c) for c in data['mouse'].flatten())\n",
    "    date = ''.join(chr(c) for c in data['date'].flatten())\n",
    "    experimenter = EXPERIMENTER_MAP.get(mouse[:2], 'Inconnu')\n",
    "\n",
    "\n",
    "\n",
    "    session_id = f\"{mouse}_{date}\"\n",
    "    start_time = datetime.strptime(date, \"%Y%m%d\")\n",
    "\n",
    "\n",
    "\n",
    "    # PART 2: Load the CSV file to extract additional metadata\n",
    "    csv_data = pd.read_csv(csv_file)\n",
    "    subject_info = csv_data[csv_data['subject_id'] == mouse].iloc[0]\n",
    "\n",
    "    # Extract additional metadata\n",
    "    age = subject_info['age']\n",
    "    genotype = subject_info['genotype']\n",
    "    sex = subject_info['sex']\n",
    "    weight = subject_info['weight']\n",
    "\n",
    "\n",
    "    \n",
    "    # Construct the output YAML path\n",
    "    config = {\n",
    "        'session_metadata': {\n",
    "            'session_id': session_id,\n",
    "            'identifier': session_id,\n",
    "            'experimenter': experimenter,\n",
    "            'description': 'Session electrophysiologie',\n",
    "            'start_time': start_time.strftime('%Y%m%d 120000'),\n",
    "            'lab': 'Petersen Lab',\n",
    "            'institution': 'EPFL'\n",
    "        },\n",
    "        'subject_metadata': {\n",
    "            'age': 'P62D',\n",
    "            'age__reference': 'birth',\n",
    "            'date_of_birth': '02/19/2025',\n",
    "            'description': 'AB164',\n",
    "            'genotype': 'WT',\n",
    "            'sex': 'F',\n",
    "            'species': 'Mus musculus',\n",
    "            'strain': 'C57BL/6',\n",
    "            'subject_id': 'AB164',\n",
    "            'weight': 15.1\n",
    "        },\n",
    "        'ephys_metadata': {\n",
    "            'processed': 1\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "        subject_metadata:\n",
    "    age: P62D\n",
    "    age__reference: birth\n",
    "    date_of_birth: 02/19/2025\n",
    "    description: AB164\n",
    "    genotype: WT\n",
    "    sex: F\n",
    "    species: Mus musculus\n",
    "    strain: C57BL/6\n",
    "    subject_id: AB164\n",
    "    weight: 15.1\n",
    "    \"\"\"\n",
    "\n",
    "    # save config\n",
    "    with open(output_path, 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "    print(f\"‚úÖ Config YAML sauvegard√© √† : {output_path}\")\n",
    "    \n",
    "    return output_path, config\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b848cdc",
   "metadata": {},
   "source": [
    "# VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5df6c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenu de 'Data' :\n",
      " - ARAindex ‚Üí shape: (75, 1), dtype: float64\n",
      " - Area ‚Üí shape: (75, 1), dtype: object\n",
      " - BaselineFR_Mean ‚Üí shape: (75, 1), dtype: float64\n",
      " - BaselineFR_Session ‚Üí shape: (75, 1), dtype: object\n",
      " - CRIndices ‚Üí shape: (1, 583), dtype: uint8\n",
      " - ClusterCounter ‚Üí shape: (75, 1), dtype: float64\n",
      " - EngagedTrials ‚Üí shape: (583, 1), dtype: uint8\n",
      " - FAIndices ‚Üí shape: (1, 583), dtype: uint8\n",
      " - HitIndices ‚Üí shape: (1, 583), dtype: uint8\n",
      " - ISI_Violation ‚Üí shape: (75, 1), dtype: float64\n",
      " - ISO_Distance ‚Üí shape: (75, 1), dtype: float64\n",
      " - JawOnsetsTms ‚Üí shape: (583, 1), dtype: float64\n",
      " - JawTrace ‚Üí shape: (583, 1000), dtype: float64\n",
      " - LFPs ‚Üí shape: (3, 1), dtype: object\n",
      " - LickData ‚Üí shape: (482142, 1), dtype: float64\n",
      " - LickTime ‚Üí shape: (482142, 1), dtype: float64\n",
      " - LightIndices ‚Üí shape: (1, 583), dtype: float64\n",
      " - MDS ‚Üí shape: (1, 1), dtype: float64\n",
      " - ML_DV_AP ‚Üí shape: (75, 1), dtype: object\n",
      " - ML_DV_AP_32 ‚Üí shape: (75, 1), dtype: object\n",
      " - MissIndices ‚Üí shape: (1, 583), dtype: uint8\n",
      " - NoseSideTrace ‚Üí shape: (583, 1000), dtype: float64\n",
      " - NoseTopTrace ‚Üí shape: (583, 1000), dtype: float64\n",
      " - QuietW_Times ‚Üí shape: (583, 1), dtype: object\n",
      " - RP_Violation ‚Üí shape: (75, 1), dtype: float64\n",
      " - ReactionTimes ‚Üí shape: (1, 583), dtype: float64\n",
      " - Spike_MainChannel ‚Üí shape: (75, 1), dtype: float64\n",
      " - SpontLicksPiezo_FakeTrialOn ‚Üí shape: (67, 1), dtype: float64\n",
      " - SpontLicksPiezo_LickOn ‚Üí shape: (67, 1), dtype: float64\n",
      " - SpontLicksVideo_FakeTrialOn ‚Üí shape: (9, 1), dtype: float64\n",
      " - SpontLicksVideo_JawOn ‚Üí shape: (7, 1), dtype: float64\n",
      " - SpontLicksVideo_TrialOn ‚Üí shape: (7, 1), dtype: float64\n",
      " - StimAmps ‚Üí shape: (1, 583), dtype: float64\n",
      " - StimIndices ‚Üí shape: (1, 583), dtype: float64\n",
      " - TongueTrace ‚Üí shape: (583, 1000), dtype: float64\n",
      " - TrialOnsets_All ‚Üí shape: (583, 1), dtype: float64\n",
      " - VideoOnsets ‚Üí shape: (583, 1), dtype: float64\n",
      " - Video_sr ‚Üí shape: (1, 1), dtype: float64\n",
      " - WhiskerAngle ‚Üí shape: (583, 1000), dtype: float64\n",
      " - Whisking_Indices ‚Üí shape: (583, 1), dtype: object\n",
      " - Whisking_Indices_NoLick ‚Üí shape: (583, 1), dtype: object\n",
      " - Whisking_Times ‚Üí shape: (583, 1), dtype: object\n",
      " - Whisking_Times_NoLick ‚Üí shape: (583, 1), dtype: object\n",
      " - clusterID ‚Üí shape: (75, 1), dtype: float64\n",
      " - date ‚Üí shape: (8, 1), dtype: uint16\n",
      " - depthHisto ‚Üí shape: (75, 1), dtype: float64\n",
      " - expert ‚Üí shape: (1, 1), dtype: float64\n",
      " - mouse ‚Üí shape: (5, 1), dtype: uint16\n",
      " - safe_name ‚Üí shape: (75, 1), dtype: object\n",
      " - session ‚Üí shape: (1, 1), dtype: float64\n",
      " - spikets ‚Üí shape: (75, 1), dtype: object\n",
      " - struct ‚Üí shape: (75, 1), dtype: object\n",
      " - struct_acr ‚Üí shape: (75, 1), dtype: object\n",
      " - threshold_amp ‚Üí shape: (1, 1), dtype: float64\n",
      " - type ‚Üí shape: (75, 1), dtype: object\n",
      " - width ‚Üí shape: (75, 1), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import h5py\n",
    "\n",
    "filename = \"AO039_20190626.mat\"  \n",
    "\n",
    "with h5py.File(filename, 'r') as f:\n",
    "    data_group = f['Data']\n",
    "    data_ref = f[\"#refs#\"]\n",
    "    #print(\"R√©f√©rences trouv√©es :\")\n",
    "    #for key in data_ref.keys():\n",
    "    #    print(f\" - {key} ‚Üí shape: {data_ref[key].shape}, dtype: {data_ref[key].dtype}\")\n",
    "    print(\"Contenu de 'Data' :\")\n",
    "    for key in data_group.keys():\n",
    "        print(f\" - {key} ‚Üí shape: {data_group[key].shape}, dtype: {data_group[key].dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15f210a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_and_open_mat(\"AO039\", \"20190626\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a8417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Config YAML sauvegard√© √† : data/AO39_20190626_config.yaml\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s‚Äôest bloqu√© lors de l‚Äôex√©cution du code dans une cellule active ou une cellule pr√©c√©dente. \n",
      "\u001b[1;31mVeuillez v√©rifier le code dans la ou les cellules pour identifier une cause possible de l‚Äô√©chec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d‚Äôinformations. \n",
      "\u001b[1;31mPour plus d‚Äôinformations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "\n",
    "filename = \"data/AO039_20190626.mat\" \n",
    "csv = \"data/Subject_Session.csv\"\n",
    "config_path, config = files_to_config(filename , csv, output_path=\"data/AO39_20190626_config.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd3cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_data_to_nwb_an(\n",
    "    config_file=config_path,\n",
    "    output_folder=\"nwb_output\",\n",
    "    with_time_string=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "702fda3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 19, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m csv_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/Subject_Session.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m csv_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nwb_env/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nwb_env/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nwb_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nwb_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nwb_env/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nwb_env/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 230\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nwb_env/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nwb_env/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nwb_env/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/nwb_env/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 19, saw 2\n"
     ]
    }
   ],
   "source": [
    "csv_data = pd.read_csv(\"data/Subject_Session.csv\")\n",
    "csv_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9725695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nwb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
